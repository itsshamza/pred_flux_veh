{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un 1er temps il faut mettre le fichier sous le meme format que les fichiers camera.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11708\\2500344291.py:9: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df['Horodatage'] = df['Horodatage'].dt.floor('H')\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_11708\\2500344291.py:11: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Sens'] = df['Voie'].replace({'Entrée Fac': 0, 'Sortie Fac': 1})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('./P2/P2_semaine_2.xlsx')\n",
    "df['Horodatage'] = pd.to_datetime(df['Horodatage'])\n",
    "df['Horodatage'] = df['Horodatage'].dt.floor('H')\n",
    "df['Sens'] = df['Voie'].replace({'Entrée Fac': 0, 'Sortie Fac': 1})\n",
    "df.drop('Voie', axis=1, inplace=True)\n",
    "df['Count'] = 1\n",
    "\n",
    "pivot_table = df.pivot_table(index=['Horodatage', 'Sens'], columns='Classe', values='Count', aggfunc='sum', fill_value=0)\n",
    "pivot_table.columns = [col for col in pivot_table.columns] \n",
    "pivot_table.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "pivot_table.to_excel('./P2_2.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenat faut assembler les 2 valeurs et les mettre dans un format similaire aux capteurs camera meme si y a un manque de type.\n",
    "\n",
    "Datetime,DayOfWeek,Sens,VELO,MOTO,VL,UT,EDPM,PL_1,PL_2,BUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Datetime  DayOfWeek  Sens  Deux roues  VL  PL  Bus\n",
      "0 2022-10-03 10:00:00          0     0           1   8   0    3\n",
      "1 2022-10-03 10:00:00          0     1           0   4   0    2\n",
      "2 2022-10-03 11:00:00          0     0          16  51   1    8\n",
      "3 2022-10-03 11:00:00          0     1           5  52   2   10\n",
      "4 2022-10-03 12:00:00          0     0           9  69   0   11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df1 = pd.read_excel('./P2_1.xlsx')\n",
    "df2 = pd.read_excel('./P2_2.xlsx')\n",
    "\n",
    "df_concatenated = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "df_concatenated.rename(columns={'Horodatage': 'Datetime'}, inplace=True)\n",
    "\n",
    "\n",
    "df_concatenated['DayOfWeek'] = df_concatenated['Datetime'].dt.dayofweek\n",
    "columns_order = ['Datetime', 'DayOfWeek', 'Sens', 'Deux roues', 'VL', 'PL', 'Bus']\n",
    "df_final = df_concatenated[columns_order]\n",
    "\n",
    "print(df_final.head())\n",
    "\n",
    "df_final.to_csv('./P2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alooors, pour P3 on trouve plein de données manquante ste des vides entre le début et la fin des fichiers.\n",
    "\n",
    "je vais travailler avec mixtra car c'est eux qui possede la majorité des fichiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_5388\\770440663.py:13: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df['Datetime'] = df['Datetime'].dt.floor('H')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./P3/Mixtra_Sortie_Fac_3.csv')\n",
    "\n",
    "df['Sens'] = 1\n",
    "df['Heure_juste'] = df['Heure'].str.split(':').str[0]\n",
    "df['Datetime'] = pd.to_datetime(df['Jour'] + ' ' + df['Heure_juste'] + ':00:00', format='%d/%m/%y %H:%M:%S')\n",
    "df['Count'] = 1\n",
    "\n",
    "df['Datetime'] = df['Datetime'].dt.floor('H')\n",
    "df.drop(['Jour', 'Heure', 'Seconde', 'Centième','Vitesse','Catégorie','Inter-essieux','E2/E3','E3/E4','E4/E5','E5/E6'], axis=1, inplace=True)\n",
    "\n",
    "pivot_table = df.pivot_table(index=['Datetime', 'Sens'], columns='Type Véhicule', values='Count', aggfunc='count', fill_value=0)\n",
    "\n",
    "pivot_table.columns = [f\"{col}\" for col in pivot_table.columns]\n",
    "pivot_table.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "pivot_table.to_excel('./P3/Mixtra_Sortie_Fac_3.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite faudra fusionner les fichiers et remplir avec les plages horaires manquantes, afin de les completer ces valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df1 = pd.read_excel('./P3/Mixtra_Sortie_Fac_1.xlsx')\n",
    "df2 = pd.read_excel('./P3/Mixtra_Sortie_Fac_2.xlsx')\n",
    "df3 = pd.read_excel('./P3/Mixtra_Sortie_Fac_3.xlsx')\n",
    "\n",
    "df_concatenated = pd.concat([df1, df2,df3], ignore_index=True)\n",
    "\n",
    "df_concatenated['DayOfWeek'] = df_concatenated['Datetime'].dt.dayofweek\n",
    "\n",
    "# Réorganiser les colonnes\n",
    "cols_order = ['Datetime', 'DayOfWeek', 'Sens', 'Trottinette', 'Vélo', 'Moto', 'VL', 'PL']\n",
    "df_concatenated = df_concatenated[cols_order]\n",
    "\n",
    "\n",
    "df_concatenated.to_csv('p3_S.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('./P3_E.csv')\n",
    "df2 = pd.read_csv('./P3_S.csv')\n",
    "\n",
    "df_concatenated = pd.concat([df1, df2], ignore_index=True)\n",
    "df_concaten = df_concatenated.sort_values(by='Datetime')\n",
    "df_concaten.to_csv('p3.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le fichier P4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_5388\\1520496975.py:11: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_entree['Datetime'] = df_entree['Datetime'].dt.floor('H')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_entree = pd.read_csv('./P4/P4_Sortie_Fac.csv')\n",
    "\n",
    "base_date = '2022-10-'\n",
    "df_entree['Datetime'] = pd.to_datetime(\n",
    "    base_date + df_entree['JOUR'].astype(str).str.zfill(2) + ' ' +\n",
    "    df_entree['HEURE/MINUTE'].astype(str).str.zfill(4).str.slice(0, 2) + ':00:00'\n",
    ")\n",
    "df_entree['Count'] = 1\n",
    "df_entree['Datetime'] = df_entree['Datetime'].dt.floor('H')\n",
    "df_entree['DayOfWeek'] = df_entree['Datetime'].dt.dayofweek\n",
    "df_entree['Sens'] = 1\n",
    "\n",
    "pivot_table = df_entree.pivot_table(index=['Datetime', 'DayOfWeek', 'Sens'], columns='TYPE', values='Count', aggfunc='count', fill_value=0)\n",
    "pivot_table.reset_index(inplace=True)\n",
    "cols_order = ['Datetime', 'DayOfWeek', 'Sens', '2R', 'VL', 'PL/Bus']\n",
    "pivot_table = pivot_table[cols_order] \n",
    "pivot_table.to_csv('P4_S.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rassembler le code entree et sortie en supprimant la colonne vélo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types présents dans les données : ['VL' 'PL' '2R']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./P5.csv')\n",
    "\n",
    "unique_types = df['TYPE'].unique()\n",
    "print(\"Types présents dans les données :\", unique_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('./P4_E.csv')\n",
    "df2 = pd.read_csv('./P4_S.csv')\n",
    "\n",
    "df1['2R'] += df1['Vélo']\n",
    "df1.drop('Vélo', axis=1, inplace=True)\n",
    "\n",
    "df_concatenated = pd.concat([df1, df2], ignore_index=True)\n",
    "df_concaten = df_concatenated.sort_values(by='Datetime')\n",
    "df_concaten.to_csv('P4.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
