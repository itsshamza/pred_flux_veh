{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types présents dans les données : ['VL' 'Bus ' 'Bus articul�' 'V�lo �lectrique' 'Trottinette' 'PL' '2RM']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./P26/P26_Vers_Fac_1.csv')#,sep=';')\n",
    "\n",
    "unique_types = df['Type Véhicule'].unique()\n",
    "print(\"Types présents dans les données :\", unique_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code dessous traite les fichiers P9_vers_Fac_1.csv P9_vers_Fac_2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test:\n",
    "vers_fac_1 :2Rm 9 in 15h\n",
    "vers_fac_2 : 2Rm 1 in 15/10 1:00 Vl 19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_23620\\3579593258.py:9: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df['Datetime'] = pd.to_datetime(df['Jour'] + ' ' + df['Heure'], format='%d/%m/%Y %H:%M').dt.floor('H')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('./P9_Vers_Talence_2.csv' ) #delimiter=';')\n",
    "\n",
    "df['Jour'] = df['Jour'].apply(lambda x: '{:02d}/{:02d}/20{}'.format(int(x.split('/')[0]), int(x.split('/')[1]), x.split('/')[2]))\n",
    "df['Datetime'] = pd.to_datetime(df['Jour'] + ' ' + df['Heure'], format='%d/%m/%Y %H:%M').dt.floor('H')\n",
    "count_by_hour = df.groupby(['Datetime', 'Type Véhicules']).size().unstack(fill_value=0)\n",
    "count_by_hour['DayOfWeek'] = count_by_hour.index.get_level_values('Datetime').dayofweek\n",
    "count_by_hour['Sens'] = 1 # = 0 pour l autre fichier \n",
    "count_by_hour = count_by_hour.reset_index()\n",
    "count_by_hour = count_by_hour[['Datetime', 'DayOfWeek', 'Sens', '2RM', 'VL', 'PL']]\n",
    "\n",
    "count_by_hour.to_csv('./P9/P9_S2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, je compte concatener les quatres fichiers pour avoir P9 finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./P9/P9_1.csv')\n",
    "df2 = pd.read_csv('./P9/P9_2.csv')\n",
    "df3 = pd.read_csv('./P9/P9_S1.csv')\n",
    "df4 = pd.read_csv('./P9/P9_S2.csv')\n",
    "\n",
    "\n",
    "df_fi = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "df_fi.sort_values(by='Datetime', inplace=True)\n",
    "df_fi.to_csv('P9.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le fichier P17\n",
    "Pl:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_entree = pd.read_csv('./P17/P17_Vers_P16.csv')\n",
    "\n",
    "base_date = '2022-10-'\n",
    "df_entree['Datetime'] = pd.to_datetime(\n",
    "    base_date + df_entree['JOUR'].astype(str).str.zfill(2) + ' ' +\n",
    "    df_entree['HEURE/MINUTE'].astype(str).str.zfill(4).str.slice(0, 2) + ':00:00'\n",
    ")\n",
    "count_by_hour = df_entree.groupby(['Datetime', 'TYPE']).size().unstack(fill_value=0)\n",
    "count_by_hour['DayOfWeek'] = count_by_hour.index.get_level_values('Datetime').dayofweek\n",
    "count_by_hour['Sens'] = 0\n",
    "\n",
    "count_by_hour = count_by_hour.reset_index()\n",
    "count_by_hour = count_by_hour[['Datetime', 'DayOfWeek', 'Sens', '2R', 'VL', 'PL']]\n",
    "\n",
    "count_by_hour.to_csv('./P17/P17_E.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rassembler P17_E et P17_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./P17/P17_E.csv')\n",
    "df2 = pd.read_csv('./P17/P17_S.csv')\n",
    "\n",
    "df_fi = pd.concat([df1, df2], ignore_index=True)\n",
    "df_fi.sort_values(by='Datetime', inplace=True)\n",
    "df_fi.to_csv('P17.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour P19 on compte le nombre de vehicules pour chaque types ensuite on  rassemble trotinettes et velo electrique avec 2RM\n",
    "E 2rm 6 , pl 1\n",
    "S 2rm 4 , pl 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_23620\\3486928476.py:7: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df['Datetime'] = pd.to_datetime(df['Jour'] + ' ' + df['Heure'], format='%d/%m/%Y %H:%M').dt.floor('H')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./P19/P19_Sortie.csv')\n",
    "\n",
    "df['Jour'] = df['Jour'].apply(lambda x: '{:02d}/{:02d}/20{}'.format(int(x.split('/')[0]), int(x.split('/')[1]), x.split('/')[2]))\n",
    "\n",
    "df['Datetime'] = pd.to_datetime(df['Jour'] + ' ' + df['Heure'], format='%d/%m/%Y %H:%M').dt.floor('H')\n",
    "\n",
    "count_by_hour = df.groupby(['Datetime', 'Type Véhicule']).size().unstack(fill_value=0)\n",
    "count_by_hour['DayOfWeek'] = count_by_hour.index.get_level_values('Datetime').dayofweek\n",
    "count_by_hour['Sens'] = 1\n",
    "count_by_hour.rename(columns={'V�lo �lectrique': 'Velo_electrique', 'Trottinette': 'Trottinette'}, inplace=True)\n",
    "count_by_hour['2RM'] = count_by_hour['2RM'] + count_by_hour['Velo_electrique'] + count_by_hour['Trottinette']\n",
    "count_by_hour.drop(columns=['Velo_electrique', 'Trottinette'], inplace=True)\n",
    "count_by_hour = count_by_hour.reset_index()\n",
    "count_by_hour = count_by_hour[['Datetime', 'DayOfWeek', 'Sens', '2RM', 'VL', 'PL']]\n",
    "\n",
    "count_by_hour.to_csv('./P19/P19_S.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv('./P19/P19_E.csv')\n",
    "df2 = pd.read_csv('./P19/P19_S.csv')\n",
    "\n",
    "df_fi = pd.concat([df1, df2], ignore_index=True)\n",
    "df_fi.sort_values(by='Datetime', inplace=True)\n",
    "\n",
    "df_fi.to_csv('P19.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite on passe pour le P23: ['VL' 'PL' '2RM' 'Bus' 'Trottinette' 'V�lo �lectrique']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_23620\\1920094164.py:7: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df['Datetime'] = pd.to_datetime(df['Jour'] + ' ' + df['Heure'], format='%d/%m/%Y %H:%M').dt.floor('H')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./P23/P23_Vers_COSEC.csv')\n",
    "\n",
    "df['Jour'] = df['Jour'].apply(lambda x: '{:02d}/{:02d}/20{}'.format(int(x.split('/')[0]), int(x.split('/')[1]), x.split('/')[2]))\n",
    "\n",
    "df['Datetime'] = pd.to_datetime(df['Jour'] + ' ' + df['Heure'], format='%d/%m/%Y %H:%M').dt.floor('H')\n",
    "\n",
    "count_by_hour = df.groupby(['Datetime', 'Type Véhicule']).size().unstack(fill_value=0)\n",
    "\n",
    "count_by_hour['DayOfWeek'] = count_by_hour.index.get_level_values('Datetime').dayofweek\n",
    "count_by_hour['Sens'] = 1\n",
    "\n",
    "count_by_hour.rename(columns={'V�lo �lectrique': 'Velo_electrique','Bus articul�': 'Bus ar', 'Trottinette': 'Trottinette'}, inplace=True)\n",
    "count_by_hour['PL'] = count_by_hour['PL'] + count_by_hour['Bus '] + count_by_hour['Bus ar']\n",
    "count_by_hour.drop(columns=['Bus ','Bus ar'], inplace=True)\n",
    "count_by_hour['2RM'] = count_by_hour['2RM'] + count_by_hour['Velo_electrique'] + count_by_hour['Trottinette']\n",
    "count_by_hour.drop(columns=['Velo_electrique', 'Trottinette'], inplace=True)\n",
    "\n",
    "count_by_hour = count_by_hour.reset_index()\n",
    "count_by_hour = count_by_hour[['Datetime', 'DayOfWeek', 'Sens', '2RM', 'VL', 'PL']]\n",
    "\n",
    "count_by_hour.to_excel('./P23/P23_S.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('./P23/P23_E1.xlsx')\n",
    "df1 = pd.read_excel('./P23/P23_E2.xlsx')\n",
    "\n",
    "df_f=pd.concat([df, df1], ignore_index=True)\n",
    "\n",
    "df_f.sort_values(by='Datetime', inplace=True)\n",
    "\n",
    "df_f.to_excel('./P23_E.xlsx',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite , je compte comparer les valeurs dans l'intervalle avec des données faussés avec la moyenne horaire par jour en dehors de cette moyenne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datetime: 2022-10-06 02:00:00, Changes: {'VL': (2, 7)}\n",
      "Datetime: 2022-10-06 06:00:00, Changes: {'VL': (3, 20), 'PL': (19, 2)}\n",
      "Datetime: 2022-10-06 07:00:00, Changes: {'2RM': (3, 8), 'VL': (26, 112), 'PL': (62, 0)}\n",
      "Datetime: 2022-10-06 08:00:00, Changes: {'2RM': (2, 10), 'VL': (27, 141), 'PL': (66, 1)}\n",
      "Datetime: 2022-10-06 09:00:00, Changes: {'VL': (28, 93), 'PL': (67, 0)}\n",
      "Datetime: 2022-10-06 10:00:00, Changes: {'2RM': (0, 4), 'VL': (17, 66), 'PL': (52, 0)}\n",
      "Datetime: 2022-10-06 11:00:00, Changes: {'2RM': (0, 4), 'VL': (28, 92), 'PL': (45, 2)}\n",
      "Datetime: 2022-10-06 12:00:00, Changes: {'2RM': (3, 11), 'VL': (70, 124), 'PL': (25, 1)}\n",
      "Datetime: 2022-10-06 13:00:00, Changes: {'VL': (32, 100), 'PL': (47, 1)}\n",
      "Datetime: 2022-10-06 14:00:00, Changes: {'2RM': (0, 4), 'VL': (19, 75), 'PL': (47, 0)}\n",
      "Datetime: 2022-10-06 15:00:00, Changes: {'2RM': (2, 6), 'VL': (23, 62), 'PL': (60, 0)}\n",
      "Datetime: 2022-10-06 16:00:00, Changes: {'VL': (30, 104), 'PL': (68, 1)}\n",
      "Datetime: 2022-10-06 17:00:00, Changes: {'2RM': (1, 6), 'VL': (77, 109), 'PL': (60, 1)}\n",
      "Datetime: 2022-10-06 18:00:00, Changes: {'2RM': (3, 8), 'PL': (32, 1)}\n",
      "Datetime: 2022-10-06 19:00:00, Changes: {'2RM': (1, 8), 'PL': (17, 0)}\n",
      "Datetime: 2022-10-06 20:00:00, Changes: {'2RM': (0, 5), 'PL': (21, 0)}\n",
      "Datetime: 2022-10-06 21:00:00, Changes: {'PL': (24, 0)}\n",
      "Datetime: 2022-10-06 22:00:00, Changes: {'PL': (16, 0)}\n",
      "Datetime: 2022-10-07 00:00:00, Changes: {'PL': (7, 0)}\n",
      "Datetime: 2022-10-07 01:00:00, Changes: {'PL': (8, 1)}\n",
      "Datetime: 2022-10-07 05:00:00, Changes: {'VL': (1, 7)}\n",
      "Datetime: 2022-10-07 06:00:00, Changes: {'VL': (8, 18), 'PL': (12, 2)}\n",
      "Datetime: 2022-10-07 07:00:00, Changes: {'2RM': (0, 5), 'VL': (8, 51)}\n",
      "Datetime: 2022-10-07 09:00:00, Changes: {'2RM': (0, 9), 'VL': (1, 60), 'PL': (2, 7)}\n",
      "Datetime: 2022-10-07 10:00:00, Changes: {'VL': (6, 47)}\n",
      "Datetime: 2022-10-07 11:00:00, Changes: {'VL': (3, 51)}\n",
      "Datetime: 2022-10-07 12:00:00, Changes: {'VL': (3, 90)}\n",
      "Datetime: 2022-10-07 13:00:00, Changes: {'VL': (0, 84)}\n",
      "Datetime: 2022-10-07 14:00:00, Changes: {'VL': (2, 67), 'PL': (0, 5)}\n",
      "Datetime: 2022-10-07 15:00:00, Changes: {'VL': (1, 80), 'PL': (0, 4)}\n",
      "Datetime: 2022-10-07 16:00:00, Changes: {'VL': (1, 80)}\n",
      "Datetime: 2022-10-07 17:00:00, Changes: {'2RM': (0, 6), 'VL': (5, 106), 'PL': (1, 5)}\n",
      "Datetime: 2022-10-07 18:00:00, Changes: {'2RM': (0, 5), 'VL': (15, 84), 'PL': (29, 4)}\n",
      "Datetime: 2022-10-07 19:00:00, Changes: {'2RM': (0, 8), 'VL': (7, 71), 'PL': (29, 3)}\n",
      "Datetime: 2022-10-07 20:00:00, Changes: {'VL': (20, 48), 'PL': (9, 2)}\n",
      "Datetime: 2022-10-07 21:00:00, Changes: {'VL': (20, 40), 'PL': (21, 2)}\n",
      "Datetime: 2022-10-07 22:00:00, Changes: {'PL': (21, 1)}\n",
      "Datetime: 2022-10-07 23:00:00, Changes: {'VL': (13, 24)}\n",
      "Datetime: 2022-10-08 00:00:00, Changes: {'VL': (5, 18), 'PL': (11, 0)}\n",
      "Datetime: 2022-10-08 01:00:00, Changes: {'VL': (9, 14)}\n",
      "Datetime: 2022-10-08 02:00:00, Changes: {'PL': (6, 2)}\n",
      "Datetime: 2022-10-08 03:00:00, Changes: {'VL': (9, 5)}\n",
      "Datetime: 2022-10-08 06:00:00, Changes: {'VL': (10, 5)}\n",
      "Datetime: 2022-10-08 08:00:00, Changes: {'VL': (12, 18)}\n",
      "Datetime: 2022-10-08 09:00:00, Changes: {'VL': (12, 50), 'PL': (24, 3)}\n",
      "Datetime: 2022-10-08 10:00:00, Changes: {'VL': (17, 43), 'PL': (36, 2)}\n",
      "Datetime: 2022-10-08 11:00:00, Changes: {'VL': (16, 42), 'PL': (28, 2)}\n",
      "Datetime: 2022-10-08 12:00:00, Changes: {'2RM': (0, 4), 'VL': (28, 61), 'PL': (38, 4)}\n",
      "Datetime: 2022-10-08 13:00:00, Changes: {'VL': (19, 57), 'PL': (31, 4)}\n",
      "Datetime: 2022-10-08 14:00:00, Changes: {'VL': (21, 46), 'PL': (29, 4)}\n",
      "Datetime: 2022-10-08 15:00:00, Changes: {'2RM': (0, 5), 'VL': (20, 59), 'PL': (27, 3)}\n",
      "Datetime: 2022-10-08 16:00:00, Changes: {'VL': (17, 54), 'PL': (31, 4)}\n",
      "Datetime: 2022-10-08 17:00:00, Changes: {'VL': (17, 54), 'PL': (47, 3)}\n",
      "Datetime: 2022-10-08 18:00:00, Changes: {'VL': (32, 57), 'PL': (26, 3)}\n",
      "Datetime: 2022-10-08 19:00:00, Changes: {'VL': (32, 50), 'PL': (27, 2)}\n",
      "Datetime: 2022-10-08 20:00:00, Changes: {'VL': (24, 41), 'PL': (31, 2)}\n",
      "Datetime: 2022-10-08 21:00:00, Changes: {'VL': (7, 17), 'PL': (17, 2)}\n",
      "Datetime: 2022-10-08 22:00:00, Changes: {'VL': (6, 20)}\n",
      "Datetime: 2022-10-08 23:00:00, Changes: {'VL': (9, 30)}\n",
      "Datetime: 2022-10-09 00:00:00, Changes: {'VL': (7, 19)}\n",
      "Datetime: 2022-10-09 01:00:00, Changes: {'VL': (5, 15), 'PL': (5, 1)}\n",
      "Datetime: 2022-10-09 02:00:00, Changes: {'2RM': (0, 4), 'VL': (2, 7)}\n",
      "Datetime: 2022-10-09 03:00:00, Changes: {'VL': (1, 6)}\n",
      "Datetime: 2022-10-09 06:00:00, Changes: {'VL': (1, 5)}\n",
      "Datetime: 2022-10-09 09:00:00, Changes: {'VL': (4, 18), 'PL': (9, 1)}\n",
      "Datetime: 2022-10-09 10:00:00, Changes: {'VL': (1, 38), 'PL': (16, 1)}\n",
      "Datetime: 2022-10-09 13:00:00, Changes: {'VL': (27, 46)}\n",
      "Datetime: 2022-10-09 14:00:00, Changes: {'VL': (45, 37)}\n",
      "Datetime: 2022-10-09 16:00:00, Changes: {'PL': (8, 2)}\n",
      "Datetime: 2022-10-09 17:00:00, Changes: {'VL': (50, 28), 'PL': (7, 2)}\n",
      "Datetime: 2022-10-09 18:00:00, Changes: {'PL': (25, 2)}\n",
      "Datetime: 2022-10-09 19:00:00, Changes: {'PL': (15, 1)}\n",
      "Datetime: 2022-10-09 20:00:00, Changes: {'PL': (15, 1)}\n",
      "Datetime: 2022-10-09 21:00:00, Changes: {'2RM': (0, 4), 'PL': (32, 1)}\n",
      "Datetime: 2022-10-09 22:00:00, Changes: {'2RM': (0, 4), 'VL': (13, 26), 'PL': (31, 1)}\n",
      "Datetime: 2022-10-09 23:00:00, Changes: {'VL': (10, 13), 'PL': (5, 0)}\n",
      "Datetime: 2022-10-10 00:00:00, Changes: {'VL': (9, 4)}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('./P23/P23_S.xlsx')\n",
    "\n",
    "valid_data = df[(df['Datetime'] < '2022-10-06') | (df['Datetime'] > '2022-10-10')]\n",
    "\n",
    "mean_values = valid_data.groupby([valid_data['Datetime'].dt.dayofweek, valid_data['Datetime'].dt.hour])[['2RM', 'VL', 'PL']].mean()\n",
    "modified_values = []\n",
    "def compare_and_adjust(row, mean_values):\n",
    "    day_of_week = row['Datetime'].dayofweek\n",
    "    hour = row['Datetime'].hour\n",
    "    mean_row = mean_values.loc[(day_of_week, hour)]\n",
    "    new_values = row[['2RM', 'VL', 'PL']]\n",
    "    changes = {}\n",
    "    \n",
    "    for col in ['2RM', 'VL', 'PL']:\n",
    "        mean_val = mean_row[col]\n",
    "        if mean_val > 10:\n",
    "            diff = 0.2 * mean_val\n",
    "        else:\n",
    "            diff = 3\n",
    "        if abs(row[col] - mean_row[col]) > diff:\n",
    "            changes[col] = (row[col], int(round(mean_row[col])))\n",
    "            new_values[col] = int(round(mean_row[col]))\n",
    "    if changes:\n",
    "        modified_values.append({'Datetime': row['Datetime'], 'Changes': changes})\n",
    "    return new_values\n",
    "\n",
    "df.loc[(df['Datetime'] >= '2022-10-06') & (df['Datetime'] <= '2022-10-10'), ['2RM', 'VL', 'PL']] = \\\n",
    "    df[(df['Datetime'] >= '2022-10-06') & (df['Datetime'] <= '2022-10-10')].apply(compare_and_adjust, axis=1, mean_values=mean_values)\n",
    "\n",
    "for item in modified_values:\n",
    "    print(f\"Datetime: {item['Datetime']}, Changes: {item['Changes']}\")\n",
    "df.to_csv('.P23_S.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('./P23_E.csv')\n",
    "df2 = pd.read_csv('./P23_S.csv')\n",
    "\n",
    "df_fi = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "\n",
    "df_fi.sort_values(by='Datetime', inplace=True)\n",
    "\n",
    "\n",
    "df_fi.to_csv('P23.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pareil pour le poste P24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_23620\\4064212454.py:7: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df['Datetime'] = pd.to_datetime(df['Jour'] + ' ' + df['Heure'], format='%d/%m/%Y %H:%M').dt.floor('H')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('./P24/P24_Vers_Rocade.csv')\n",
    "\n",
    "df['Jour'] = df['Jour'].apply(lambda x: '{:02d}/{:02d}/20{}'.format(int(x.split('/')[0]), int(x.split('/')[1]), x.split('/')[2]))\n",
    "\n",
    "df['Datetime'] = pd.to_datetime(df['Jour'] + ' ' + df['Heure'], format='%d/%m/%Y %H:%M').dt.floor('H')\n",
    "\n",
    "count_by_hour = df.groupby(['Datetime', 'Type Véhicule']).size().unstack(fill_value=0)\n",
    "\n",
    "count_by_hour['DayOfWeek'] = count_by_hour.index.get_level_values('Datetime').dayofweek\n",
    "count_by_hour['Sens'] = 1\n",
    "\n",
    "count_by_hour.rename(columns={'V�lo �lectrique': 'Velo_electrique', 'Trottinette': 'Trottinette'}, inplace=True)\n",
    "count_by_hour['2RM'] = count_by_hour['2RM'] + count_by_hour['Velo_electrique'] + count_by_hour['Trottinette']\n",
    "count_by_hour.drop(columns=['Velo_electrique', 'Trottinette'], inplace=True)\n",
    "\n",
    "count_by_hour = count_by_hour.reset_index()\n",
    "count_by_hour = count_by_hour[['Datetime', 'DayOfWeek', 'Sens', '2RM', 'VL', 'PL']]\n",
    "\n",
    "count_by_hour.to_excel('./P24/P24_s.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ici j ai eu un petit souci c'est que les intervalles non presnetes dans le compte ne sont pas present sur le fichier excel et donc j'ai eu des trous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4420\\1672615697.py:3: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  date_range = pd.date_range(start=df['Datetime'].min(), end=df['Datetime'].max(), freq='H')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('./P24/P24_s.xlsx')\n",
    "date_range = pd.date_range(start=df['Datetime'].min(), end=df['Datetime'].max(), freq='H')\n",
    "\n",
    "full_range_df = pd.DataFrame(date_range, columns=['Datetime'])\n",
    "df_full = pd.merge(full_range_df, df, on='Datetime', how='left')\n",
    "\n",
    "df_full[['2RM', 'VL', 'PL']] = df_full[['2RM', 'VL', 'PL']].fillna(0)\n",
    "df_full['Sens'] = df_full['Sens'].ffill().bfill()\n",
    "df_full['DayOfWeek'] = df_full['Datetime'].dt.dayofweek\n",
    "\n",
    "df_full.to_excel('./P24/P24_scomplet.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datetime: 2022-10-10 09:00:00, Changes: {'VL': (26, 90)}\n",
      "Datetime: 2022-10-10 10:00:00, Changes: {'VL': (2, 49)}\n",
      "Datetime: 2022-10-10 11:00:00, Changes: {'VL': (1, 69)}\n",
      "Datetime: 2022-10-10 12:00:00, Changes: {'2RM': (0, 4), 'VL': (0, 80)}\n",
      "Datetime: 2022-10-10 13:00:00, Changes: {'VL': (1, 143)}\n",
      "Datetime: 2022-10-10 14:00:00, Changes: {'VL': (0, 82)}\n",
      "Datetime: 2022-10-10 15:00:00, Changes: {'VL': (0, 79)}\n",
      "Datetime: 2022-10-10 16:00:00, Changes: {'2RM': (0, 7), 'VL': (2, 157)}\n",
      "Datetime: 2022-10-10 17:00:00, Changes: {'2RM': (0, 6), 'VL': (1, 226)}\n",
      "Datetime: 2022-10-10 18:00:00, Changes: {'2RM': (0, 5), 'VL': (0, 210)}\n",
      "Datetime: 2022-10-10 19:00:00, Changes: {'2RM': (0, 6), 'VL': (0, 120)}\n",
      "Datetime: 2022-10-10 20:00:00, Changes: {'2RM': (1, 5), 'VL': (2, 58)}\n",
      "Datetime: 2022-10-10 21:00:00, Changes: {'VL': (4, 44)}\n",
      "Datetime: 2022-10-10 22:00:00, Changes: {'VL': (1, 39)}\n",
      "Datetime: 2022-10-10 23:00:00, Changes: {'VL': (1, 10)}\n",
      "Datetime: 2022-10-11 00:00:00, Changes: {'VL': (1, 6)}\n",
      "Datetime: 2022-10-11 01:00:00, Changes: {'VL': (1, 6)}\n",
      "Datetime: 2022-10-11 06:00:00, Changes: {'VL': (1, 7)}\n",
      "Datetime: 2022-10-11 07:00:00, Changes: {'2RM': (1, 5), 'VL': (2, 68)}\n",
      "Datetime: 2022-10-11 08:00:00, Changes: {'VL': (2, 144)}\n",
      "Datetime: 2022-10-11 09:00:00, Changes: {'VL': (0, 71)}\n",
      "Datetime: 2022-10-11 10:00:00, Changes: {'VL': (0, 31)}\n",
      "Datetime: 2022-10-11 11:00:00, Changes: {'VL': (1, 86)}\n",
      "Datetime: 2022-10-11 12:00:00, Changes: {'2RM': (0, 5), 'VL': (2, 100)}\n",
      "Datetime: 2022-10-11 13:00:00, Changes: {'2RM': (0, 4), 'VL': (1, 119)}\n",
      "Datetime: 2022-10-11 14:00:00, Changes: {'VL': (0, 71)}\n",
      "Datetime: 2022-10-11 15:00:00, Changes: {'VL': (0, 90)}\n",
      "Datetime: 2022-10-11 16:00:00, Changes: {'2RM': (0, 6), 'VL': (0, 172)}\n",
      "Datetime: 2022-10-11 17:00:00, Changes: {'2RM': (1, 10), 'VL': (1, 292)}\n",
      "Datetime: 2022-10-11 18:00:00, Changes: {'2RM': (0, 8), 'VL': (1, 290)}\n",
      "Datetime: 2022-10-11 19:00:00, Changes: {'2RM': (0, 6), 'VL': (0, 140)}\n",
      "Datetime: 2022-10-11 20:00:00, Changes: {'2RM': (0, 6), 'VL': (0, 72)}\n",
      "Datetime: 2022-10-11 21:00:00, Changes: {'VL': (1, 37)}\n",
      "Datetime: 2022-10-11 22:00:00, Changes: {'VL': (3, 30)}\n",
      "Datetime: 2022-10-11 23:00:00, Changes: {'VL': (1, 17)}\n",
      "Datetime: 2022-10-12 00:00:00, Changes: {'VL': (1, 11)}\n",
      "Datetime: 2022-10-12 06:00:00, Changes: {'VL': (2, 10)}\n",
      "Datetime: 2022-10-12 07:00:00, Changes: {'2RM': (0, 4), 'VL': (6, 81)}\n",
      "Datetime: 2022-10-12 08:00:00, Changes: {'2RM': (1, 6), 'VL': (0, 140)}\n",
      "Datetime: 2022-10-12 09:00:00, Changes: {'VL': (0, 92)}\n",
      "Datetime: 2022-10-12 10:00:00, Changes: {'VL': (0, 35)}\n",
      "Datetime: 2022-10-12 11:00:00, Changes: {'VL': (0, 62)}\n",
      "Datetime: 2022-10-12 12:00:00, Changes: {'2RM': (0, 9), 'VL': (0, 119)}\n",
      "Datetime: 2022-10-12 13:00:00, Changes: {'2RM': (2, 10), 'VL': (0, 138)}\n",
      "Datetime: 2022-10-12 14:00:00, Changes: {'VL': (1, 79)}\n",
      "Datetime: 2022-10-12 15:00:00, Changes: {'2RM': (1, 5), 'VL': (0, 115)}\n",
      "Datetime: 2022-10-12 16:00:00, Changes: {'2RM': (0, 7), 'VL': (0, 193)}\n",
      "Datetime: 2022-10-12 17:00:00, Changes: {'2RM': (0, 7), 'VL': (1, 239)}\n",
      "Datetime: 2022-10-12 18:00:00, Changes: {'VL': (1, 203)}\n",
      "Datetime: 2022-10-12 19:00:00, Changes: {'VL': (1, 112)}\n",
      "Datetime: 2022-10-12 20:00:00, Changes: {'VL': (3, 49)}\n",
      "Datetime: 2022-10-12 21:00:00, Changes: {'VL': (0, 27)}\n",
      "Datetime: 2022-10-12 22:00:00, Changes: {'VL': (0, 34)}\n",
      "Datetime: 2022-10-12 23:00:00, Changes: {'VL': (5, 14)}\n",
      "Datetime: 2022-10-13 00:00:00, Changes: {'VL': (3, 13)}\n",
      "Datetime: 2022-10-13 06:00:00, Changes: {'VL': (0, 11)}\n",
      "Datetime: 2022-10-13 07:00:00, Changes: {'VL': (12, 103)}\n",
      "Datetime: 2022-10-13 08:00:00, Changes: {'2RM': (0, 6), 'VL': (1, 173)}\n",
      "Datetime: 2022-10-13 09:00:00, Changes: {'2RM': (0, 6), 'VL': (0, 96)}\n",
      "Datetime: 2022-10-13 10:00:00, Changes: {'VL': (0, 52)}\n",
      "Datetime: 2022-10-13 11:00:00, Changes: {'VL': (0, 84)}\n",
      "Datetime: 2022-10-13 12:00:00, Changes: {'2RM': (0, 5), 'VL': (1, 100)}\n",
      "Datetime: 2022-10-13 13:00:00, Changes: {'VL': (1, 121)}\n",
      "Datetime: 2022-10-13 14:00:00, Changes: {'2RM': (0, 4), 'VL': (57, 98)}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('./P24/P24_scomplet.xlsx')\n",
    "\n",
    "valid_data = df[(df['Datetime'] < '2022-10-10 09:00:00') | (df['Datetime'] > '2022-10-13 15:00:00')]\n",
    "\n",
    "mean_values = valid_data.groupby([valid_data['Datetime'].dt.dayofweek, valid_data['Datetime'].dt.hour])[['2RM', 'VL', 'PL']].mean()\n",
    "modified_values = []\n",
    "def compare_and_adjust(row, mean_values):\n",
    "    day_of_week = row['Datetime'].dayofweek\n",
    "    hour = row['Datetime'].hour\n",
    "#    if (day_of_week, hour) in mean_values.index:\n",
    "    mean_row = mean_values.loc[(day_of_week, hour)]\n",
    "    new_values = row[['2RM', 'VL', 'PL']]\n",
    "    changes = {}\n",
    "    \n",
    "    for col in ['2RM', 'VL', 'PL']:\n",
    "        mean_val = mean_row[col]\n",
    "        if mean_val > 10:\n",
    "            diff = 0.2 * mean_val\n",
    "        else:\n",
    "            diff = 3\n",
    "        if abs(row[col] - mean_row[col]) > diff:\n",
    "            changes[col] = (row[col], int(round(mean_row[col])))\n",
    "            new_values[col] = int(round(mean_row[col]))\n",
    "    if changes:\n",
    "        modified_values.append({'Datetime': row['Datetime'], 'Changes': changes})\n",
    "    return new_values\n",
    "\n",
    "df.loc[(df['Datetime'] >= '2022-10-10 09:00:00') & (df['Datetime'] <= '2022-10-13 15:00:00'), ['2RM', 'VL', 'PL']] = \\\n",
    "    df[(df['Datetime'] >= '2022-10-10 09:00:00') & (df['Datetime'] <= '2022-10-13 15:00:00')].apply(compare_and_adjust, axis=1, mean_values=mean_values)\n",
    "\n",
    "for item in modified_values:\n",
    "    print(f\"Datetime: {item['Datetime']}, Changes: {item['Changes']}\")\n",
    "df.to_csv('./P24/P24_s.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = pd.read_csv('./P24/P24_e.csv')\n",
    "df2 = pd.read_csv('./P24/P24_s.csv')\n",
    "\n",
    "df_fi = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "\n",
    "df_fi.sort_values(by='Datetime', inplace=True)\n",
    "\n",
    "\n",
    "df_fi.to_csv('P24.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et pour le poste 26 j'ai apprsi qu il faut concatener mieux sinon y aura repetitions de lignes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4420\\2086628044.py:9: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df['Datetime'] = pd.to_datetime(df['Jour'] + ' ' + df['Heure'], format='%d/%m/%Y %H:%M').dt.floor('H')\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('./P26/P26_Vers_Rocade_1.csv')\n",
    "df2 = pd.read_csv('./P26/P26_Vers_Rocade_2.csv')\n",
    "#df3 = pd.read_csv('./P26/P26_Vers_Fac_3.csv')\n",
    "\n",
    "df = pd.concat([df1, df2])\n",
    "\n",
    "df['Jour'] = df['Jour'].apply(lambda x: '{:02d}/{:02d}/20{}'.format(int(x.split('/')[0]), int(x.split('/')[1]), x.split('/')[2]))\n",
    "\n",
    "df['Datetime'] = pd.to_datetime(df['Jour'] + ' ' + df['Heure'], format='%d/%m/%Y %H:%M').dt.floor('H')\n",
    "\n",
    "count_by_hour = df.groupby(['Datetime', 'Type Véhicule']).size().unstack(fill_value=0)\n",
    "\n",
    "count_by_hour['DayOfWeek'] = count_by_hour.index.get_level_values('Datetime').dayofweek\n",
    "count_by_hour['Sens'] = 1\n",
    "\n",
    "count_by_hour.rename(columns={'V�lo �lectrique': 'Velo_electrique','Bus articul�': 'Bus ar', 'Trottinette': 'Trottinette'}, inplace=True)\n",
    "count_by_hour['PL'] = count_by_hour['PL'] + count_by_hour['Bus '] + count_by_hour['Bus ar']\n",
    "count_by_hour.drop(columns=['Bus ','Bus ar'], inplace=True)\n",
    "count_by_hour['2RM'] = count_by_hour['2RM'] + count_by_hour['Velo_electrique'] + count_by_hour['Trottinette']\n",
    "count_by_hour.drop(columns=['Velo_electrique', 'Trottinette'], inplace=True)\n",
    "\n",
    "count_by_hour = count_by_hour.reset_index()\n",
    "count_by_hour = count_by_hour[['Datetime', 'DayOfWeek', 'Sens', '2RM', 'VL', 'PL']]\n",
    "\n",
    "count_by_hour.to_csv('./P26/P26_s.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_4420\\1137404569.py:4: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  date_range = pd.date_range(start=df['Datetime'].min(), end=df['Datetime'].max(), freq='H')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('./P26/P26_e.csv')\n",
    "df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "\n",
    "date_range = pd.date_range(start=df['Datetime'].min(), end=df['Datetime'].max(), freq='H')\n",
    "\n",
    "full_range_df = pd.DataFrame(date_range, columns=['Datetime'])\n",
    "df_full = pd.merge(full_range_df, df, on='Datetime', how='left')\n",
    "\n",
    "df_full[['2RM', 'VL', 'PL']] = df_full[['2RM', 'VL', 'PL']].fillna(0).astype('Int64')\n",
    "df_full['Sens'] = df_full['Sens'].ffill().bfill().astype('Int64')\n",
    "df_full['DayOfWeek'] = df_full['Datetime'].dt.dayofweek.astype('Int64')\n",
    "\n",
    "df_full.to_csv('./P26/P26_ecomplet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = pd.read_csv('./P26/P26_ecomplet.csv')\n",
    "df2 = pd.read_csv('./P26/P26_scomplet.csv')\n",
    "\n",
    "df_fi = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "\n",
    "df_fi.sort_values(by='Datetime', inplace=True)\n",
    "\n",
    "\n",
    "df_fi.to_csv('P26.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
